# About

This allows you to serve your ollama api to other apps without any restriction. I have tried to use ollama api in my applications, but ollama only serve to local and don’t support cors. So I created this project to serve the ollama api to all over network and even internet.

# Requirements


1. [Ollama](https://ollama.com/download) (As it’s redirect the ollama response through the port, you absulately need ollama installed on your system.

# Installation

* npm i
* npm run start

And you server will run at your specific port. In the script I set it to 8981.

# APIs

Same as ollama, so no need to do any extra work, just change the ollama port to this one in your existing project

# Tasks

- [x] Enable model list api
- [ ] Replace test html with <https://github.com/mmar58/Ollama-Chat>


