# About

This allows you to serve your ollama api to other apps without any restriction. I have tried to use ollama api in my applications, but ollama only serve to local and don’t support cors. So I created this project to serve the ollama api to all over network and even internet.

# Requirements


1. [Ollama](https://ollama.com/download) (As it’s redirect the ollama response through the port, you absulately need ollama installed on your system.

# Installation

* npm i
* npm start

And you server will run at your specific port. In the script I set it to 8981.

# APIs

You can use direct link of the port to use the test html `(/public/index.html)` to test the apis

# Tasks

- [ ] Enable model list api
- [ ] Replace test html with <https://github.com/mmar58/Ollama-Chat>


